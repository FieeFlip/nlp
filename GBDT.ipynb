{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def stg_agg(n, c1, c2):\n",
    "    return math.sqrt((c2/ n) - (c1 / n)**2)\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, x, y, idxs=None, min_leaf=2):\n",
    "        if idxs is None:\n",
    "            idxs = np.arange(len(y))\n",
    "        self.x, self.y, self.idxs, self.min_leaf = x, y, idxs, min_leaf\n",
    "        \n",
    "        # n个数，c列的个数\n",
    "        self.n, self.c = len(idxs), x.shape[1]\n",
    "        # 在idxs的均值\n",
    "        self.val = np.mean(y[idxs])\n",
    "        self.score = float('inf')\n",
    "        self.find_varsplit()\n",
    "        \n",
    "    def find_varsplit(self):\n",
    "        for i in range(self.c):\n",
    "            self.find_better_split(i)\n",
    "            \n",
    "        if self.score == float('inf'):\n",
    "            return\n",
    "        \n",
    "        x = self.split_col\n",
    "        # 获取左右子树的索引\n",
    "        lhs = np.nonzero(x <= self.split)[0]\n",
    "        rhs = np.nonzero(x > self.split)[0]\n",
    "        self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n",
    "        self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])\n",
    "        \n",
    "    def find_better_split(self, var_idx):\n",
    "        # var_idx：第var_idx个特征， idx横坐标\n",
    "        x, y = self.x.values[self.idxs, var_idx], self.y[self.idxs]\n",
    "        # 获取排序后的索引值\n",
    "        sort_idx = np.argsort(x)\n",
    "        # 获取排序之后的值\n",
    "        sort_x, sort_y = x[sort_idx], y[sort_idx]\n",
    "        # 一开始全是右子树\n",
    "        rhs_cnt, rhs_sum, rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()\n",
    "        \n",
    "        lhs_cnt, lhs_sum, lhs_sum2 = 0, 0., 0.\n",
    "        \n",
    "        # 一个一个分给左子树\n",
    "        for i in range(0, self.n - self.min_leaf - 1): # 保证右子树最少min_leaf个结点\n",
    "            xi, yi = sort_x[i], sort_y[i]\n",
    "            rhs_cnt -= 1; lhs_cnt += 1\n",
    "            rhs_sum -= yi; lhs_sum += yi\n",
    "            rhs_sum2 -= yi**2; lhs_sum2 += yi**2\n",
    "            # 当左子树结点小于min_leaf，或者xi == x[i+1]则不进行划分了\n",
    "            if i < self.min_leaf or xi == sort_x[i+1]:\n",
    "                continue\n",
    "            # 划分标准\n",
    "            lhs_std = stg_agg(lhs_cnt, lhs_sum, lhs_sum2)\n",
    "            rhs_std = stg_agg(rhs_cnt, rhs_sum, rhs_sum2)\n",
    "            curr_score = lhs_std*lhs_cnt + rhs_cnt*rhs_std\n",
    "            if curr_score < self.score:\n",
    "                self.var_idx, self.score, self.split = var_idx, curr_score, xi\n",
    "                \n",
    "    @property\n",
    "    def split_name(self): \n",
    "        return self.x.columns[self.var_idx]\n",
    "    \n",
    "    @property\n",
    "    def split_col(self):\n",
    "        return self.x.values[self.idxs, self.var_idx]\n",
    "    \n",
    "    # 判断本决策树是否是叶子节点，则此时self.var是叶子节点的值，其他情况是均值\n",
    "    @property\n",
    "    def is_leaf(self): \n",
    "        return self.score == float('inf')\n",
    "    \n",
    "    # 输出对象的格式\n",
    "    def __repr__(self):\n",
    "        s = f'n:{self.n}; var:{self.var}'\n",
    "        if not is_leaf():\n",
    "            s = f'score:{self.score}; split:{self.split}; var:{self.var}'\n",
    "        return s\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.array([self.predict_row(xi) for xi in x])\n",
    "    \n",
    "    def predict_row(self, xi):\n",
    "        if is_leaf:\n",
    "            return self.var\n",
    "        t = self.lhs if xi[self.var_idx] < self.split else self.rhs\n",
    "        return t.predict_row(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "x = np.arange(0,50)\n",
    "x = pd.DataFrame({'x':x})\n",
    "\n",
    "y1 = np.random.uniform(10,15,10)\n",
    "y2 = np.random.uniform(20,25,10)\n",
    "y3 = np.random.uniform(0,5,10)\n",
    "y4 = np.random.uniform(30,32,10)\n",
    "y5 = np.random.uniform(13,17,10)\n",
    "\n",
    "y = np.concatenate((y1,y2,y3,y4,y5))\n",
    "y = y[:,None] \n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(x,y, 'o')\n",
    "plt.title(\"Scatter plot of x vs. y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = x # initialization of input\n",
    "yi = y # initialization of target\n",
    "# x,y --> use where no need to change original y\n",
    "ei = 0 # initialization of error\n",
    "n = len(yi)  # number of rows\n",
    "predf = 0 # initial prediction 0\n",
    "\n",
    "for i in range(30): # like n_estimators\n",
    "    tree = DecisionTree(xi,yi)\n",
    "    tree.find_better_split(0)\n",
    "    \n",
    "    r = np.where(xi == tree.split)[0][0]    \n",
    "    \n",
    "    left_idx = np.where(xi <= tree.split)[0]\n",
    "    right_idx = np.where(xi > tree.split)[0]\n",
    "    \n",
    "    predi = np.zeros(n)\n",
    "    np.put(predi, left_idx, np.repeat(np.mean(yi[left_idx]), r))  # replace left side mean y\n",
    "    np.put(predi, right_idx, np.repeat(np.mean(yi[right_idx]), n-r))  # right side mean y\n",
    "    \n",
    "    predi = predi[:,None]  # make long vector (nx1) in compatible with y\n",
    "    predf = predf + predi  # final prediction will be previous prediction value + new prediction of residual\n",
    "    \n",
    "    ei = y - predf  # needed originl y here as residual always from original y    \n",
    "    yi = ei # update yi as residual to reloop\n",
    "    \n",
    "    \n",
    "    # plotting after prediction\n",
    "    xa = np.array(x.x) # column name of x is x \n",
    "    order = np.argsort(xa)\n",
    "    xs = np.array(xa)[order]\n",
    "    ys = np.array(predf)[order]\n",
    "    \n",
    "    #epreds = np.array(epred[:,None])[order]\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize = (13,2.5))\n",
    "\n",
    "    ax1.plot(x,y, 'o')\n",
    "    ax1.plot(xs, ys, 'r')\n",
    "    ax1.set_title(f'Prediction (Iteration {i+1})')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y / y_pred')\n",
    "\n",
    "    ax2.plot(x, ei, 'go')\n",
    "    ax2.set_title(f'Residuals vs. x (Iteration {i+1})')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('Residuals') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而梯度提升树相关的模型，例如XGBoost，LightGBM，CatBoost等在建模的时候则往往不需要对特征进行归一化，对于特征中出现的极大极小值也有较好的鲁棒性<br>\n",
    "- 传统的表格(Tabular)类模型，基于梯度提升树的模型往往可以取得更好的成绩，我们对这些历史竞赛进行了统计，发现对于表格型的数据算法竞赛，超过90%以上的获奖方案目前都都是基于梯度提升树模型的。目前有些特定的领域，例如推荐，销量预测等问题慢慢地神经网络也展露头角；\n",
    "- 图像，NLP，序列化等非Tabular类的模型，Top的方案主要基于各种神经网络的；虽然早期也会有一些传统方案的，例如随机森林等，但是最近几年已经全部演化为了神经网络相关的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我们的目标是最小化$L(y, F(x)$，那么我们只需要做到$L(y, \\sum_{i=1}^t f_i(x) + f_{t+1}(x))$的值比$L(y, \\sum_{i=1}^tf_i(x))$尽可能的小。<br>\n",
    "此处我们进一步假设问题的$\\color{red}{损失函数L是可导的}$，这个假设在目前的很多问题中都是非常通用的，毕竟目前的常用的损失函数一半以上都是可导的。<br>\n",
    "\n",
    "即最大化$$max[L(y, \\sum_{i=1}^t f_i(x) + f_{t+1}(x)) - L(y, \\sum_{i=1}^tf_i(x))]$$\n",
    "令$c = \\sum_{i=1}^t f_i(x)$,则$$max[L(y, c + f_{t+1}(x)) - L(y, c)]$$\n",
    "根据泰勒公式：$$L(c + f_{t+1}(x)) \\approx L(c) + L^{'}(c)f_{t+1}(X)$$\n",
    "若$f_{t+1}(x) = -1 * L^{'}(c)$,则大约$$L(c + f_{t+1}(x)) = L(c) - L^{'}(c)^2 < L(c)$$\n",
    "所以用第t+1个决策树来拟合$f_{t+1}(x) = -1 * L^{'}(c)$，即拟合$\\color{red}{梯度}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9583333333333334, 0.9504166666666667]\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "data_list  = [datasets.load_iris(), datasets.load_digits()]\n",
    "data_list  = [(d.data, d.target) for d in data_list]\n",
    "data_list += [datasets.make_hastie_10_2()]\n",
    "names      = ['Iris Data', 'Digits Data', 'Hastie Data']\n",
    "\n",
    "n_gb       = []\n",
    "score_g    = []\n",
    "time_gb    = [] \n",
    "score_gb   = [] \n",
    "n_estimators = 500\n",
    "\n",
    "for X, y in data_list:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                        random_state=0)\n",
    " \n",
    "    gb = ensemble.GradientBoostingClassifier(n_estimators=n_estimators,random_state=0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    score_gb.append(gb.score(X_test, y_test))  \n",
    "    n_gb.append(gb.n_estimators_) \n",
    "print(score_gb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
